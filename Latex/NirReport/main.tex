\documentclass[specialist, substylefile = spbureport.rtx,
    subf,href,colorlinks=true, 12pt]{disser}

% \usepackage[a4paper, mag=1000, includefoot,
%     left=2cm, right=1.5cm, top=2cm, bottom=2cm, headsep=1cm, footskip=1cm]{geometry}

\usepackage[a4paper, top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry}

\usepackage[T1,T2A]{fontenc}

\usepackage{graphicx}
\graphicspath{ {images/} }
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm} %for \newtheorem*
\usepackage[english,russian]{babel}

% \pagestyle{plain}

\newtheorem*{definition}{Определение}
\newtheorem*{example}{Пример}
\newtheorem*{hypothesis}{Гипотеза}
\newtheorem*{question}{Вопрос}
\newtheorem*{algorithm}{Алгоритм}

\newcommand{\rank}{\mathsf{rank}\ }
\newcommand{\T}{\mathcal{T}}
\newcommand{\F}{\mathsf{F}}
\newcommand{\MF}{\vec{\F}}
\newcommand{\sfS}{\mathsf{S}}
\newcommand{\sfR}{\mathsf{R}}
\newcommand{\MS}{\vec{\sfS}}
\newcommand{\MSE}{\mathsf{MSE}}
\newcommand{\mean}{\mathsf{mean}}
\newcommand{\X}{\mathbf{X}}
\newcommand{\wX}{\overset{\wedge}{\X}}






\institution{Санкт-Петербургский государственный университет\\
    Математико-механический факультет\\
    Кафедра Статистического Моделирования
}
\title{«Научно-исследовательская работа» (семестр 6)}
\topic{Поддерживающие временные ряды в MSSA}
\author{Ткаченко Егор Андреевич}
\group{группа 19.Б04-мм}
\sa       {Голяндина Нина Эдуардовна}
\sastatus {к.\,ф.-м.\,н., доцент}
\city{Санкт-Петербург}
\date{2022}


\begin{document}

    \maketitle
    \pagebreak
    \tableofcontents
    \pagebreak

    \intro
        Полезность умения строить прогнозы не нуждается в доказательстве. Прогноз временных рядов может использоваться в прогнозе погоды, приливов, спроса на товары и многом другом.
         
        С помощью книги \cite{SSA_with_R} был изучен базовый SSA, разложение рядов, заполнение пробелов в данных, прогноз и базовый MSSA. Для работы с временными рядами и их прогнозом использовался пакет Rssa. Проведены эксперименты с простейшими моделями сигналов для изучения связи между согласованностью сигналов и поддерживающими рядами.



        % После этого я изучал 
    % \chapter{обозначения}
    \section{Определения}
        Вещественным временным рядом длины $N$ называется вектор
        $$\F = (f_0, \dots, f_{N - 1}),\ f_j \in \mathbb{R}.$$

        Многомерным временным рядом $\MF$ называется набор $s$ временных рядов $\F^{(p)}$ длин $N_p$:
        $$\MF = \{\F^{(p)} = (f^{(p)}_0, \dots, f^{(p)}_{N_p - 1}),\ p=1, \dots, s\}.$$

        $L$-траекторная матрица (или просто траекторная матрица) ряда $\F$ имеет структуру ганкелевой матрицы, а ее столбцами являются отрезки длины L ряда $\F$
        $$\T_{SSA}(\F) =
        \begin{pmatrix}
            f_0     & f_1    & \dots  & f_{K-1} \\
            f_1     & f_2    & \dots  & f_K     \\
            \vdots  & \vdots & \ddots & \vdots  \\
            f_{L-1} & f_L    & \dots  & f_{N-1} \\
        \end{pmatrix}.$$
        $L$-траекторная матрица многомерного ряда $\MF$ состоит из горизонтально склеенных траекторных матриц рядов $\F^{(p)} \in \MF$:
        $$\T_{MSSA}(\MF) = [\T_{SSA}(\F^{(1)}): \dotso :\T_{SSA}(\F^{(s)})].$$
        Из траекторной матрицы можно восстановить ряд. Из любой матрицы подходящего размера можно получить траекторную матрицу проектированием на пространство ганкелевых матриц (или склеенных горизонтально ганкелевых матриц для многомерного случая).

        Ранг ряда равен рангу его траекторной матрицы:
        $$\rank \F = \rank \T_{SSA}(\F),\qquad \rank \MF = \rank \T_{MSSA}(\MF).$$

        


    \section{Применение SSA и MSSA}

        Алгоритмы SSA и MSSA могут быть применены для аппроксимации временного ряда рядом конечного ранга.

        \begin{algorithm}\ \\
            \textbf{Вход:} Ряд $\F$ для SSA или многомерный ряд $\MF$ для MSSA,
            длина окна $L \leq N$ для SSA или $L \leq N_p, \forall N_p$ для MSSA,
            ранг аппроксимирующего ряда r.

            \begin{enumerate}
                \item[1] Вложение. Временной ряд переводится в L-траекторную матрицу $\X$
                    $$\X = \T_{SSA}(\F) \text{ для SSA,\qquad } \X = \T_{MSSA}(\MF) \text{ для MSSA.}$$
                \item[2] Сингулярное разложение. Методом SVD матрица $\X$ раскладывается на сумму $d$ матриц 
                $\X_i = \sqrt{\lambda_i}U_iV_i^T$, где $d = \rank \X = \rank \X\X^T \leq L$,
                $\lambda_i$ --- собственные числа матрицы $\X\X^T$ ($\lambda_1 \geq \dotso \geq \lambda_L \geq 0$),
                $U_i$ --- собственные вектора матрицы $\X\X^T$,
                $V_i = \X^T U_i / \sqrt{\lambda_i}$ --- факторные вектора матрицы $\X$.
                \item[3] Группировка. Множество индексов $\{1, \dots, d\}$ делится на $m$ непересекающихся множеств $I_1 ,\dots, I_m$. Далее для каждого множества индексов (пусть $I = {i_1, \dots, i_t}$) получается матрица $\X_I = \X_{i_1} + \dots + \X_{i_t}$.\\
                Для аппроксимации рядом конечного ранга $r$, понадобится множество из первых $r$ индексов $\{1, \dots, r\}$, соответствующую ему матрицу обозначу $\wX_r = \X_1 + \dots + \X_r$.
                \item[4] 
                Сгруппированные матрицы $\X_{I_j}$ восстанавливаются в ряды (SSA) или многомерные ряды (MSSA).
                Для получения аппроксимирующего ряда нужно восстановить его из матрицы $\wX_r$.
            \end{enumerate}
            \textbf{Выход:} Аппроксимирующий ряд $\overset{\wedge}{\F}_r$ конечного ранга r.
        \end{algorithm}

    \section{ЛРФ}
        Линейная рекуррентная формула (ЛРФ) выражает каждый член последовательности через линейную комбинацию предыдущих членов.

        Ряд $\F$ длины $N$ --- управляемый ЛРФ, если существуют такие $a_1, \dotso, a_d$, что:
        $$f_{i+d} = \sum_{k=1}^d a_k f_{i+d-k},\ 0 \leq i \leq N - 1 - d,\ a_d \neq 0,\ t < N - 1.$$
        Важно отметить, что ряд конечного ранга является управляемым ЛРФ \cite[2.1.2.2, стр. 35]{SSA_with_R}.
        
        

        Вещественный временной ряд $\F$, управляемый ЛРФ, естественным образом прогнозируется на одну точку:
        $$\overset{\sim}{f}_{N} = \sum_{k=1}^{L-1} a_k f_{N-k}.$$
        Но тогда его можно прогнозировать и на любое количество точек.
        % $$\overset{\sim}{\F}_{N_p} = (\overset{\sim}{f}_{N_p}, \dots, \overset{\sim}{f}_{N_p + \overset{\sim}{N}_p - 1}), \overset{\sim}{f_j} \in \mathbb{R}.$$
        % Также ряд управляемый ЛРФ, естественным образом можно прогнозировать на одно значение, а значит и на любое количество значений.

        % \begin{block}{Коэффициенты ЛРФ $a_1, \dotso, a_{L-1}$}
        %     $$(a_1, \dotso, a_{L-1}) = \mathcal{R}_L=\frac{1}{1-\sum_{j=1}^r \pi(U_j)^2} \sum_{j=1}^r \pi(U_j) \underline{U_j},$$
        %     где $\pi(U_j)$ --- последняя координата вектора $U_j$,\\ $\underline{U_j}$ --- вектор $U_j$ без последней координаты.
        % \end{block}



    \chapter{Постановка задачи}

        Пусть имеется временной ряд $\F^{(1)} = \sfS^{(1)} + \sfR^{(1)}$, где сигнал $\sfS^{(1)}$ --- ряд управляемый ЛРФ, шум~$\sfR^{(1)}$ --- ряд без структуры. Рассмотрим задачу прогнозирования $\sfS^{(1)}$. Эта задача уже решается методом SSA, но как можно улучшить прогноз?

        Пусть помимо ряда $\F^{(1)}$ имеется временной ряд $\F^{(2)} = \sfS^{(2)} + \sfR^{(2)}$.
        Если структура сигналов $\sfS^{(1)}$ и $\sfS^{(2)}$ похожа, то использование ряда $\F^{(2)}$ может улучшить прогноз сигнала $\sfS^{(1)}$, потому что второй ряд дает алгоритму больше данных, которые могут улучшить ЛРФ.
        Возможность такого улучшения прогноза подтверждена \cite[4.3.3.3, стр. 216]{SSA_with_R}.
        Но второй ряд может сделать прогноз хуже, если структура его сигнала отличается от первого.

        Простейший пример похожих по структуре сигналов --- гармонические колебания с одинаковыми периодом. Они даже могут быть смещены по фазе или иметь разную амплитуду.

        Для объективной оценки качества прогноза буду использовать среднюю квадратичную ошибку.
        $$\mathsf{MSE(\overset{\sim}{S},\ S)} = \frac{1}{N_{f}} \sum_{i = N}^{N + N_{f} - 1} (\overset{\sim}{s}_i - s_i)^2,$$
        где $\overset{\sim}{\sfS}$ --- прогноз сигнала $\sfS$ на $N_{f}$ точек, $N$ --- длина прогнозируемого сигнала $\sfS$.
    

        Ряд $F^{(2)}$ называется поддерживающим для прогноза, если прогноз с его использованием лучше чем без него, т.е.
    
        $$\MSE(\overset{\sim}{\sfS}_{MSSA},\ \sfS^{(1)}) < \MSE(\overset{\sim}{\sfS}_{SSA},\ \sfS^{(1)}).$$
        Такое определение можно применить только в экспериментах с известным продолжением ряда. На практике не с чем сравнить прогноз, поэтому появляется вопрос. Как понять, что ряд поддерживающий не зная продолжения прогнозируемого ряда? Помочь ответить на этот вопрос может понятие согласованности.

        Сигналы $\sfS^{(1)}$, $\sfS^{(2)}$ называются полностью согласованными, если ранг $r_{1,2} = r_1 = r_2$ и полностью несогласованными, если $r_{1,2} = r_1 + r_2$, где $r_1 = \rank \sfS^{(1)}$, $r_2 = \rank \sfS^{(2)}$, $r_{1,2} = \rank \MS = \rank \{\sfS^{(1)}, \sfS^{(2)}\}.$

    \section{Примеры}
        когда следует ожидать, что MSSA лучше
        % \begin{example}

        %     \begin{tabular}{lll}
        %     & $s^{(i)}_j = A_i\cos(\frac{2\pi j}{T_i})$ & $s^{(i)}_j = A_i\exp(j\lambda_i)$ \\
        %     Согласованные:  & $T_1 = T_2 \neq 2$ & $\lambda_1 = \lambda_2$
        %     \\
        %     Несогласованные:& $2 \neq T_1 \neq T_2 \neq 2$ & $\lambda_1 \neq \lambda_2$
        %     \end{tabular}
        % \end{example}

    \chapter{Численные эксперименты}
        
    \section{Выбор компонент для MSSA}
        Гипотеза: Когда сигналы похожи, их можно считать согласованными и лучше использовать (при прогнозе или восстановлении сигнала) ранг равный рангу одного сигнала. Когда сигналы отличаются, их следует считать не согласованными и использовать ранг равный сумме рангов сигналов.

        Выберем первый ряд как простой сигнал, зависящий от параметра (например, период) с аддитивным гауссовым шумом.
        Второй ряд будет простым сигналом того же вида, с несколько отличающимся параметром и без шума.
        Восстановим и спрогнозируем первый ряд с помощью $SSA$, $MSSA$ считая ряды согласованными и $MSSA$ считая ряды несогласованными.

        Для устойчивости результатов, повторим это 50 раз и возьмем среднее ошибок.

        Назовем относительной ошибкой прогноза (восстановления) значение $$\displaystyle \frac{error_{SSA} - error_{MSSA}}{error_{SSA} + error_{MSSA}},$$ где $error_{SSA}, error_{MSSA}$ --- ошибки прогноза (восстановления) методами $SSA$ и $MSSA$ соответственно.
        
        Значения относительной ошибки легко расположить на графике (она принимает значения от -1 до 1). По значению относительной ошибки легче понять, какой метод лучше (не надо сравнивать два значения ошибок, которые просто положительны и могут быть любых порядков).
        
        Как интерпретировать значения относительной ошибки? 
        \begin{itemize}
            \item Значения $>0$ значат, что что $MSSA$ лучше $SSA$;
            \item Значения $<0$ значат, что что $MSSA$ хуже $SSA$;
            \item значения около $0$ значат что ошибки примерно равны.
            \item значения далеко от $0$ значат, что ошибки сильно отличаются.
        \end{itemize}

        Так же все сигналы будут нормироваться, чтобы амплитуда сигнала не влияла на ошибки прогноза и восстановления. Например, для косинуса: $s_j^{(i)} = A \cos(\frac{2\pi j}{T_i})$, где $A = \mean(|s_j^{(i)}|)^{-1}$.


    \subsection{Сигнал косинус}
        Сигнал $\sfS^{(1)}$ --- косинус с периодом $8$.
        Сигналы $\sfS^{(2)}$ --- косинусы с периодами $8$, $8.02$, $8.04$, $8.06$, $8.08$, $8.1$, $8.15$.

        Ранг косинуса равен 2, поэтому для $MSSA$ используются первые 2 или первые 4 компоненты разложения, а для $SSA$ только 2.

        \begin{figure}[h]
            \centering
            \includegraphics[width=\textwidth]{experiment_1_cos.pdf}
            \caption{Зависимость относительных ошибок от разницы сигналов и выбора ранга для $MSSA$}
            \label{fig:exp1_cos}
        \end{figure}

        На рис. \ref{fig:exp1_cos} видим подтверждение гипотезы: с увеличением разницы рядов использование четырех компонент становится лучше.

    \subsection{Сигнал экспонента}
        Функция для сигналов --- $s^{(i)}_j = A \exp(j\lambda_i)$.
        Сигнал $\sfS^{(1)}$ --- экспоненциальная функция c $\lambda = $.
        Сигналы $\sfS^{(2)}$ --- косинусы с периодами $8$, $8.02$, $8.04$, $8.06$, $8.08$, $8.1$, $8.15$.

        Ранг косинуса равен 2, поэтому для $MSSA$ используются первые 2 или первые 4 компоненты разложения, а для $SSA$ только 2.

        \begin{figure}[h]
            \centering
            \includegraphics[width=\textwidth]{experiment_1_exp.pdf}
            \caption{Зависимость относительных ошибок от разницы сигналов и выбора ранга для $MSSA$}
            \label{fig:exp1_exp}
        \end{figure}

        На рис. \ref{fig:exp1_exp} видим подтверждение гипотезы: с увеличением разницы рядов использование четырех компонент становится лучше.

    







        







    \section{старое}
        Выдвинута гипотеза, что ряд $\F^{(2)}$ поддерживающий для ряда $\F^{(1)}$, если их сигналы $\sfS^{(1)}$, $\sfS^{(2)}$ согласованны и шум $\sfR^{(2)}$ небольшой.

        Так как на практике могут встречаться отклонения от полностью согласованных сигналов, хочется узнать, на сколько можно исказить сигнал второго ряда, прежде чем он перестанет быть поддерживающим?

        Для подтверждения гипотезы и ответа на вопрос была проведена серия описанных ниже экспериментов.

        Временные ряды строились как сумма сигнала и шума.
        В качестве моделей сигнала использовались функции из списка:
            \begin{enumerate}
                \item $s^{(i)}_j = \exp(j\lambda_i);$
                \item $s^{(i)}_j = \cos(\frac{2\pi j}{12})\exp(j\lambda_i);$
                \item $s^{(i)}_j = \cos(\frac{2\pi j}{T_i});$
                \item $s^{(i)}_j = \cos(\frac{2\pi j}{12}) + \exp(j\lambda_i).$
            \end{enumerate}
        Параметр первого сигнала (период косинуса $T_1$ или база показательный функции $\lambda_1$) фиксировался, параметр второго сигнала менялся, начиная с такого же значения как у первого, до момента, когда второй ряд переставал быть поддерживающим.
        В качестве шума для обоих рядов использовались независимые белые гауссовские шумы со средними, равными 0, и дисперсиями $\sigma_1^2, \sigma_2^2$, соответственно.



    \section{старые Результаты}
        
        Гипотеза была подтверждена для всех четырех моделей сигнала. Ряд, сигнал которого полностью согласован с сигналом прогнозируемого, перестает быть поддерживающим, если его шум слишком большой.

        Показательные функции, умноженные на косинус с общим периодом, оставались поддерживающими дольше, чем показательные функции без косинусов.
        Показательные функции, к которым был прибавлен косинус, тоже были поддерживающими дольше, чем показательные функции без косинусов.
        


    \conclusion
        В будущем планируется дальнейшее изучение зависимости согласованности от структуры рядов, рассмотрение случаев, когда ряды имеют разные ранги. 

        % В направлении 
        Использование SSA и MSSA сложно автоматизировать, потому что алгоритму требуются дополнительные параметры, лучший выбор которых не очевиден. Возможно, будет разработан метод поиска оптимальных входных параметров.        

        
        % \begin{itemize}
        %     \item Как по структуре рядов понять согласованность?
        %     \item Что если ранги рядов разные?
        % \end{itemize}

    
    % \section{Литература}
	% \nocite{L1}

	\renewcommand{\refname}{}
	\vspace{-25pt}
	\bibliographystyle{ugost2008}
	\bibliography{references}
\end{document}